{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5adbda3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 15:35:19.123191: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-13 15:35:20.287371: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-13 15:35:22.634178: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-13 15:35:23.000519: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pnd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "#Définition de la longueur et de la largeur de l'image\n",
    "LONGUEUR_IMAGE = 28\n",
    "LARGEUR_IMAGE = 28\n",
    "\n",
    "#Chargement des images\n",
    "observations_entrainement = pnd.read_csv('datas/fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace50442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array(observations_entrainement.iloc[:, 1:])\n",
    "\n",
    "premiereImage = X[0]\n",
    "premiereImage = premiereImage.reshape([LONGUEUR_IMAGE,LARGEUR_IMAGE])\n",
    "plt.imshow(premiereImage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5191e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = keras.utils.to_categorical(np.array(observations_entrainement.iloc[:,0]))\n",
    "X_apprentissage, X_validation, y_apprentissage, y_validation = train_test_split(X, y, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6403ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_apprentissage = X_apprentissage.reshape(X_apprentissage.shape[0], \n",
    "                                          LARGEUR_IMAGE, \n",
    "                                          LONGUEUR_IMAGE, 1)\n",
    "X_apprentissage = X_apprentissage.astype('float32')\n",
    "X_apprentissage /= 255\n",
    "\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], \n",
    "                                    LARGEUR_IMAGE, \n",
    "                                    LONGUEUR_IMAGE, 1)\n",
    "X_validation = X_validation.astype('float32')\n",
    "X_validation /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c32bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_test = pnd.read_csv('datas/fashion-mnist_test.csv')\n",
    "X_test = np.array(observations_test.iloc[:, 1:])\n",
    "y_test = tf.keras.utils.to_categorical(np.array(observations_test.iloc[:, 0]))\n",
    "X_test = X_test.reshape(X_test.shape[0], \n",
    "                        LARGEUR_IMAGE, \n",
    "                        LONGUEUR_IMAGE, 1)\n",
    "X_test = X_test.astype('float32')\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f22f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "dimentionImage = (LARGEUR_IMAGE, LONGUEUR_IMAGE, 1)\n",
    "\n",
    "reseauNeurone1Convolution = Sequential()\n",
    "\n",
    "reseauNeurone1Convolution.add(Input(shape=dimentionImage))\n",
    "\n",
    "reseauNeurone1Convolution.add(Conv2D(32, \n",
    "                                     kernel_size=(3, 3), \n",
    "                                     activation='relu'))\n",
    "\n",
    "reseauNeurone1Convolution.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "reseauNeurone1Convolution.add(Dropout(0.2))\n",
    "\n",
    "reseauNeurone1Convolution.add(Flatten())\n",
    "\n",
    "reseauNeurone1Convolution.add(Dense(128, activation='relu'))\n",
    "\n",
    "reseauNeurone1Convolution.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa1f9a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reseauNeurone1Convolution.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                                  optimizer=tf.keras.optimizers.Adam(), \n",
    "                                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d73ced2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 15:35:29.183002: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 150528000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.8061 - loss: 0.5578 - val_accuracy: 0.8634 - val_loss: 0.3899\n",
      "Epoch 2/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.8731 - loss: 0.3616 - val_accuracy: 0.8808 - val_loss: 0.3403\n",
      "Epoch 3/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.8878 - loss: 0.3182 - val_accuracy: 0.8804 - val_loss: 0.3299\n",
      "Epoch 4/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.8945 - loss: 0.2939 - val_accuracy: 0.8942 - val_loss: 0.3058\n",
      "Epoch 5/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.9033 - loss: 0.2725 - val_accuracy: 0.8992 - val_loss: 0.2866\n",
      "Epoch 6/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.9095 - loss: 0.2546 - val_accuracy: 0.9015 - val_loss: 0.2802\n",
      "Epoch 7/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 55ms/step - accuracy: 0.9131 - loss: 0.2414 - val_accuracy: 0.8997 - val_loss: 0.2785\n",
      "Epoch 8/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.9168 - loss: 0.2313 - val_accuracy: 0.9038 - val_loss: 0.2697\n",
      "Epoch 9/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.9220 - loss: 0.2180 - val_accuracy: 0.9084 - val_loss: 0.2539\n",
      "Epoch 10/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 45ms/step - accuracy: 0.9251 - loss: 0.2087 - val_accuracy: 0.9103 - val_loss: 0.2520\n"
     ]
    }
   ],
   "source": [
    "historique_apprentissage = reseauNeurone1Convolution.fit(\n",
    "    X_apprentissage, \n",
    "    y_apprentissage,\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce13bfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur: 0.2402944564819336\n",
      "Précision: 0.9165999889373779\n"
     ]
    }
   ],
   "source": [
    "evaluation = reseauNeurone1Convolution.evaluate(X_test, y_test, verbose=0)\n",
    "print('Erreur:', evaluation[0])\n",
    "print('Précision:', evaluation[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5193cde4",
   "metadata": {},
   "source": [
    "plt.plot(historique_apprentissage.history['accuracy'])\n",
    "plt.plot(historique_apprentissage.history['val_accuracy'])\n",
    "plt.title('Précision du modèle')\n",
    "plt.ylabel('Précision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Apprentissage', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "# Plot training & validation loss values\n",
    "plt.plot(historique_apprentissage.history['loss'])\n",
    "plt.plot(historique_apprentissage.history['val_loss'])\n",
    "plt.title('Erreur')\n",
    "plt.ylabel('Erreur')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Apprentissage', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ee8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "generateur_images = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=8,\n",
    "    width_shift_range=0.08,\n",
    "    shear_range=0.3,\n",
    "    height_shift_range=0.08,\n",
    "    zoom_range=0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e29e6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - accuracy: 0.8259 - loss: 0.4672 - val_accuracy: 0.8440 - val_loss: 0.4186\n",
      "Epoch 2/50\n",
      "\u001b[1m  1/187\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 59ms/step - accuracy: 0.8320 - loss: 0.4312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8320 - loss: 0.4312 - val_accuracy: 0.8409 - val_loss: 0.4213\n",
      "Epoch 3/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.8456 - loss: 0.4164 - val_accuracy: 0.8549 - val_loss: 0.3924\n",
      "Epoch 4/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8594 - loss: 0.3926 - val_accuracy: 0.8545 - val_loss: 0.3890\n",
      "Epoch 5/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 78ms/step - accuracy: 0.8541 - loss: 0.3928 - val_accuracy: 0.8643 - val_loss: 0.3727\n",
      "Epoch 6/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8945 - loss: 0.3848 - val_accuracy: 0.8580 - val_loss: 0.3838\n",
      "Epoch 7/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 85ms/step - accuracy: 0.8597 - loss: 0.3785 - val_accuracy: 0.8616 - val_loss: 0.3627\n",
      "Epoch 8/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8398 - loss: 0.3989 - val_accuracy: 0.8643 - val_loss: 0.3647\n",
      "Epoch 9/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - accuracy: 0.8646 - loss: 0.3701 - val_accuracy: 0.8699 - val_loss: 0.3558\n",
      "Epoch 10/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8750 - loss: 0.3822 - val_accuracy: 0.8667 - val_loss: 0.3572\n",
      "Epoch 11/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 112ms/step - accuracy: 0.8663 - loss: 0.3611 - val_accuracy: 0.8750 - val_loss: 0.3428\n",
      "Epoch 12/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8516 - loss: 0.4261 - val_accuracy: 0.8758 - val_loss: 0.3420\n",
      "Epoch 13/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.8699 - loss: 0.3550 - val_accuracy: 0.8695 - val_loss: 0.3455\n",
      "Epoch 14/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8672 - loss: 0.3283 - val_accuracy: 0.8723 - val_loss: 0.3455\n",
      "Epoch 15/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - accuracy: 0.8727 - loss: 0.3443 - val_accuracy: 0.8732 - val_loss: 0.3442\n",
      "Epoch 16/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8672 - loss: 0.3269 - val_accuracy: 0.8722 - val_loss: 0.3415\n",
      "Epoch 17/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 77ms/step - accuracy: 0.8742 - loss: 0.3373 - val_accuracy: 0.8735 - val_loss: 0.3403\n",
      "Epoch 18/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8984 - loss: 0.2917 - val_accuracy: 0.8657 - val_loss: 0.3432\n",
      "Epoch 19/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 93ms/step - accuracy: 0.8752 - loss: 0.3331 - val_accuracy: 0.8794 - val_loss: 0.3303\n",
      "Epoch 20/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8672 - loss: 0.3252 - val_accuracy: 0.8766 - val_loss: 0.3332\n",
      "Epoch 21/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.8758 - loss: 0.3304 - val_accuracy: 0.8764 - val_loss: 0.3281\n",
      "Epoch 22/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8438 - loss: 0.3856 - val_accuracy: 0.8794 - val_loss: 0.3285\n",
      "Epoch 23/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - accuracy: 0.8785 - loss: 0.3235 - val_accuracy: 0.8765 - val_loss: 0.3294\n",
      "Epoch 24/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8555 - loss: 0.3401 - val_accuracy: 0.8778 - val_loss: 0.3301\n",
      "Epoch 25/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - accuracy: 0.8836 - loss: 0.3190 - val_accuracy: 0.8803 - val_loss: 0.3181\n",
      "Epoch 26/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8711 - loss: 0.2923 - val_accuracy: 0.8838 - val_loss: 0.3172\n",
      "Epoch 27/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.8818 - loss: 0.3191 - val_accuracy: 0.8800 - val_loss: 0.3147\n",
      "Epoch 28/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8828 - loss: 0.2945 - val_accuracy: 0.8792 - val_loss: 0.3198\n",
      "Epoch 29/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 74ms/step - accuracy: 0.8843 - loss: 0.3129 - val_accuracy: 0.8865 - val_loss: 0.3048\n",
      "Epoch 30/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9141 - loss: 0.2137 - val_accuracy: 0.8837 - val_loss: 0.3059\n",
      "Epoch 31/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 65ms/step - accuracy: 0.8857 - loss: 0.3054 - val_accuracy: 0.8767 - val_loss: 0.3236\n",
      "Epoch 32/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9102 - loss: 0.2201 - val_accuracy: 0.8828 - val_loss: 0.3194\n",
      "Epoch 33/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 75ms/step - accuracy: 0.8858 - loss: 0.3061 - val_accuracy: 0.8890 - val_loss: 0.3043\n",
      "Epoch 34/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.9141 - loss: 0.2508 - val_accuracy: 0.8882 - val_loss: 0.2962\n",
      "Epoch 35/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.8906 - loss: 0.2974 - val_accuracy: 0.8841 - val_loss: 0.3120\n",
      "Epoch 36/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8633 - loss: 0.3680 - val_accuracy: 0.8849 - val_loss: 0.3096\n",
      "Epoch 37/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 80ms/step - accuracy: 0.8884 - loss: 0.2998 - val_accuracy: 0.8917 - val_loss: 0.2978\n",
      "Epoch 38/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.8984 - loss: 0.2868 - val_accuracy: 0.8900 - val_loss: 0.2929\n",
      "Epoch 39/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.8904 - loss: 0.2964 - val_accuracy: 0.8892 - val_loss: 0.3024\n",
      "Epoch 40/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8633 - loss: 0.3474 - val_accuracy: 0.8881 - val_loss: 0.3045\n",
      "Epoch 41/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - accuracy: 0.8914 - loss: 0.2926 - val_accuracy: 0.8923 - val_loss: 0.2916\n",
      "Epoch 42/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8828 - loss: 0.2852 - val_accuracy: 0.8951 - val_loss: 0.2869\n",
      "Epoch 43/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 109ms/step - accuracy: 0.8918 - loss: 0.2909 - val_accuracy: 0.8949 - val_loss: 0.2928\n",
      "Epoch 44/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8945 - loss: 0.3125 - val_accuracy: 0.8902 - val_loss: 0.2953\n",
      "Epoch 45/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 110ms/step - accuracy: 0.8909 - loss: 0.2912 - val_accuracy: 0.8911 - val_loss: 0.2927\n",
      "Epoch 46/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9102 - loss: 0.2619 - val_accuracy: 0.8899 - val_loss: 0.2952\n",
      "Epoch 47/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.8927 - loss: 0.2877 - val_accuracy: 0.8851 - val_loss: 0.3061\n",
      "Epoch 48/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9258 - loss: 0.2175 - val_accuracy: 0.8867 - val_loss: 0.3105\n",
      "Epoch 49/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 110ms/step - accuracy: 0.8949 - loss: 0.2847 - val_accuracy: 0.8940 - val_loss: 0.2867\n",
      "Epoch 50/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8906 - loss: 0.2546 - val_accuracy: 0.8912 - val_loss: 0.2888\n",
      "Erreur : 0.22899682819843292\n",
      "Précision: 0.9182000160217285\n"
     ]
    }
   ],
   "source": [
    "nouvelles_images_apprentissage = generateur_images.flow(\n",
    "    X_apprentissage, \n",
    "    y_apprentissage,\n",
    "    batch_size=256)\n",
    "\n",
    "nouvelles_images_validation = generateur_images.flow(\n",
    "    X_validation, \n",
    "    y_validation,\n",
    "    batch_size=256)\n",
    "\n",
    "historique_apprentissage = reseauNeurone1Convolution.fit(\n",
    "    nouvelles_images_apprentissage,\n",
    "    steps_per_epoch=48000//256,\n",
    "    epochs=50,\n",
    "    validation_data=nouvelles_images_validation,\n",
    "    validation_steps=12000//256,\n",
    "    verbose=1 )\n",
    "\n",
    "evaluation = reseauNeurone1Convolution.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Erreur :', evaluation[0])\n",
    "print('Précision:', evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c6c5bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé !\n"
     ]
    }
   ],
   "source": [
    "#Sauvegarde du modèle\n",
    "# Serialisation du modèle \n",
    "model_json = reseauNeurone1Convolution.to_json() \n",
    "with open(\"modele/modele.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "    \n",
    "# Serialisation des poids\n",
    "reseauNeurone1Convolution.save_weights(\"modele/modele.weights.h5\")\n",
    "print(\"Modèle sauvegardé !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a3ff27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "\n",
    "reseauNeurones4Convolution = Sequential()\n",
    "\n",
    "reseauNeurones4Convolution.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=dimentionImage))\n",
    "reseauNeurones4Convolution.add(BatchNormalization())\n",
    "reseauNeurones4Convolution.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "reseauNeurones4Convolution.add(BatchNormalization())\n",
    "reseauNeurones4Convolution.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "reseauNeurones4Convolution.add(Dropout(0.25))\n",
    "\n",
    "reseauNeurones4Convolution.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "reseauNeurones4Convolution.add(BatchNormalization())\n",
    "reseauNeurones4Convolution.add(Dropout(0.25))\n",
    "\n",
    "reseauNeurones4Convolution.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "reseauNeurones4Convolution.add(BatchNormalization())\n",
    "reseauNeurones4Convolution.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "reseauNeurones4Convolution.add(Dropout(0.25))\n",
    "\n",
    "reseauNeurones4Convolution.add(Flatten())\n",
    "reseauNeurones4Convolution.add(Dense(512, activation='relu'))\n",
    "reseauNeurones4Convolution.add(BatchNormalization())\n",
    "reseauNeurones4Convolution.add(Dropout(0.5))\n",
    "\n",
    "reseauNeurones4Convolution.add(Dense(128, activation='relu'))\n",
    "reseauNeurones4Convolution.add(BatchNormalization())\n",
    "reseauNeurones4Convolution.add(Dropout(0.5))\n",
    "\n",
    "reseauNeurones4Convolution.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "855b0cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 15:45:35.537814: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 150528000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 300ms/step - accuracy: 0.7427 - loss: 0.7530 - val_accuracy: 0.1185 - val_loss: 3.7044\n",
      "Epoch 2/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 290ms/step - accuracy: 0.8434 - loss: 0.4381 - val_accuracy: 0.5406 - val_loss: 1.8336\n",
      "Epoch 3/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 293ms/step - accuracy: 0.8672 - loss: 0.3729 - val_accuracy: 0.8183 - val_loss: 0.5146\n",
      "Epoch 4/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 292ms/step - accuracy: 0.8803 - loss: 0.3344 - val_accuracy: 0.8953 - val_loss: 0.2867\n",
      "Epoch 5/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 294ms/step - accuracy: 0.8899 - loss: 0.3091 - val_accuracy: 0.8980 - val_loss: 0.2756\n",
      "Epoch 6/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 310ms/step - accuracy: 0.8978 - loss: 0.2884 - val_accuracy: 0.9023 - val_loss: 0.2609\n",
      "Epoch 7/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 297ms/step - accuracy: 0.9012 - loss: 0.2719 - val_accuracy: 0.9058 - val_loss: 0.2614\n",
      "Epoch 8/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 305ms/step - accuracy: 0.9076 - loss: 0.2603 - val_accuracy: 0.9012 - val_loss: 0.2723\n",
      "Epoch 9/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 293ms/step - accuracy: 0.9104 - loss: 0.2497 - val_accuracy: 0.9144 - val_loss: 0.2356\n",
      "Epoch 10/10\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 293ms/step - accuracy: 0.9134 - loss: 0.2407 - val_accuracy: 0.9156 - val_loss: 0.2353\n"
     ]
    }
   ],
   "source": [
    "reseauNeurones4Convolution.compile(loss=keras.losses.categorical_crossentropy, \n",
    "                                  optimizer=tf.keras.optimizers.Adam(), \n",
    "                                  metrics=['accuracy'])\n",
    "\n",
    "historique_apprentissage = reseauNeurones4Convolution.fit(\n",
    "    X_apprentissage, \n",
    "    y_apprentissage,\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6deb0f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur: 0.2201380878686905\n",
      "Précision: 0.9243000149726868\n"
     ]
    }
   ],
   "source": [
    "evaluation = reseauNeurones4Convolution.evaluate(X_test, y_test, verbose=0)\n",
    "print('Erreur:', evaluation[0])\n",
    "print('Précision:', evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a09efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 290ms/step - accuracy: 0.8536 - loss: 0.4037 - val_accuracy: 0.8572 - val_loss: 0.3935\n",
      "Epoch 2/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.8359 - loss: 0.4284 - val_accuracy: 0.8629 - val_loss: 0.3749\n",
      "Epoch 3/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 283ms/step - accuracy: 0.8714 - loss: 0.3575 - val_accuracy: 0.8746 - val_loss: 0.3494\n",
      "Epoch 4/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8516 - loss: 0.3943 - val_accuracy: 0.8772 - val_loss: 0.3406\n",
      "Epoch 5/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 295ms/step - accuracy: 0.8756 - loss: 0.3456 - val_accuracy: 0.8681 - val_loss: 0.3516\n",
      "Epoch 6/50\n",
      "\u001b[1m187/187\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.8320 - loss: 0.4554 - val_accuracy: 0.8763 - val_loss: 0.3308\n",
      "Epoch 7/50\n"
     ]
    }
   ],
   "source": [
    "historique_apprentissage = reseauNeurones4Convolution.fit(\n",
    "    nouvelles_images_apprentissage,\n",
    "    steps_per_epoch=48000//256,\n",
    "    epochs=50,\n",
    "    validation_data=nouvelles_images_validation,\n",
    "    validation_steps=12000//256,\n",
    "    verbose=1 )\n",
    "\n",
    "evaluation = reseauNeurones4Convolution.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Erreur :', evaluation[0])\n",
    "print('Précision:', evaluation[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
